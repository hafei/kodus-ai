/**
 * Kodus AI Diff å¤„ç†å®Œæ•´æµç¨‹ - å¯è°ƒè¯•ç‰ˆæœ¬
 * 
 * åŒ…å«æ‰€æœ‰æ ¸å¿ƒæ­¥éª¤ï¼š
 * 1. Diff å¤„ç† (handlePatchDeletions, convertToHunksWithLinesNumbers)
 * 2. ä¸Šä¸‹æ–‡æ‰©å±• (extractRelevantContext, getRelatedContentFromDiff æ¨¡æ‹Ÿ)
 * 3. AST åˆ†ææ¥å£ (FunctionAffect, å½±å“åˆ†æ)
 * 4. MCP å·¥å…·è°ƒç”¨æ¨¡æ‹Ÿ
 */

// ============================================================================
// ç±»å‹å®šä¹‰
// ============================================================================

export interface FileInfo {
    filename: string;
    patch?: string;
    status?: 'modified' | 'added' | 'deleted';
    fileContent?: string;
}

export interface ModifiedRange {
    start: number;
    end: number;
}

export interface FunctionAffect {
    functionName: string;
    filePath: string;
    impact: string;
    affectedBy: string[];
}

export interface ImpactAnalysisResponse {
    functionsAffect: FunctionAffect[];
    functionSimilarity: Array<{
        functionName: string;
        filePath: string;
        similarTo: Array<{
            functionName: string;
            filePath: string;
            similarity: number;
        }>;
    }>;
}

export interface ProcessingStep {
    step: number;
    name: string;
    description: string;
    input: any;
    output: any;
    tokensBefore?: number;
    tokensAfter?: number;
    tokensSaved?: string;
    duration?: number;
}

export interface ContextEvidence {
    provider: string;
    toolName: string;
    payload: any;
    metadata?: Record<string, unknown>;
}

export interface AnalysisContext {
    file: FileInfo;
    patchWithLinesStr: string;
    modifiedRanges: ModifiedRange[];
    relevantContent?: string;
    impactAnalysis?: ImpactAnalysisResponse;
    contextEvidences?: ContextEvidence[];
    processingSteps: ProcessingStep[];
}

// ============================================================================
// Step 1: Diff å¤„ç†
// ============================================================================

const RE_HUNK_HEADER = /^@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@[ ]?(.*)/;

/**
 * Step 1.1: ç§»é™¤åªåˆ é™¤çš„ hunks
 */
export function handlePatchDeletions(
    patch: string,
    fileName: string,
    editType: string,
): string | null {
    if (!patch && editType !== 'modified' && editType !== 'added') {
        return null;
    }

    const patchLines = patch?.split('\n') || [];
    const tempHunk: string[] = [];
    const addedPatched: string[] = [];
    let addHunk = false;
    let insideHunk = false;

    for (const line of patchLines) {
        if (line.startsWith('@@')) {
            const match = line.match(RE_HUNK_HEADER);
            if (match) {
                if (insideHunk && addHunk) {
                    addedPatched.push(...tempHunk);
                }
                tempHunk.length = 0;
                addHunk = false;
                tempHunk.push(line);
                insideHunk = true;
            }
        } else {
            tempHunk.push(line);
            if (line.charAt(0) === '+') {
                addHunk = true;
            }
        }
    }

    if (insideHunk && addHunk) {
        addedPatched.push(...tempHunk);
    }

    return addedPatched.join('\n');
}

/**
 * Step 1.2: æ·»åŠ ç»å¯¹è¡Œå·
 */
export function convertToHunksWithLinesNumbers(
    patch: string,
    file: FileInfo,
): string {
    let patchWithLinesStr = `\n\n## file: '${file.filename?.trim() || 'unknown'}'\n`;
    const patchLines = patch.split('\n');

    let newContentLines: string[] = [];
    let oldContentLines: string[] = [];
    let match: RegExpMatchArray | null = null;
    let start1 = -1, size1 = -1, start2 = -1, size2 = -1;
    let prevHeaderLine = '';
    let headerLine = '';

    for (const line of patchLines) {
        if (line.toLowerCase().includes('no newline at end of file')) {
            continue;
        }

        if (line.startsWith('@@')) {
            headerLine = line;
            match = line.match(RE_HUNK_HEADER);

            if (match && (newContentLines.length > 0 || oldContentLines.length > 0)) {
                if (prevHeaderLine) {
                    patchWithLinesStr += `\n${prevHeaderLine}\n`;
                }

                if (newContentLines.length > 0) {
                    const isPlusLines = newContentLines.some(l => l.startsWith('+'));
                    if (isPlusLines) {
                        patchWithLinesStr = patchWithLinesStr.trimEnd() + '\n__new hunk__\n';
                        for (let i = 0; i < newContentLines.length; i++) {
                            patchWithLinesStr += `${start2 + i} ${newContentLines[i]}\n`;
                        }
                    }
                }

                if (oldContentLines.length > 0) {
                    const isMinusLines = oldContentLines.some(l => l.startsWith('-'));
                    if (isMinusLines) {
                        patchWithLinesStr = patchWithLinesStr.trimEnd() + '\n__old hunk__\n';
                        for (const lineOld of oldContentLines) {
                            patchWithLinesStr += `${lineOld}\n`;
                        }
                    }
                }

                newContentLines = [];
                oldContentLines = [];
            }

            if (match) {
                prevHeaderLine = headerLine;
                const res = match.slice(1, 5).map(val => parseInt(val || '0', 10));
                [start1, size1, start2, size2] = res;
            }
        } else if (line.startsWith('+')) {
            newContentLines.push(line);
        } else if (line.startsWith('-')) {
            oldContentLines.push(line);
        } else {
            newContentLines.push(line);
            oldContentLines.push(line);
        }
    }

    if (match && newContentLines.length > 0) {
        patchWithLinesStr += `\n${headerLine}\n`;
        if (newContentLines.length > 0) {
            const isPlusLines = newContentLines.some(l => l.startsWith('+'));
            if (isPlusLines) {
                patchWithLinesStr = patchWithLinesStr.trimEnd() + '\n__new hunk__\n';
                for (let i = 0; i < newContentLines.length; i++) {
                    patchWithLinesStr += `${start2 + i} ${newContentLines[i]}\n`;
                }
            }
        }
        if (oldContentLines.length > 0) {
            const isMinusLines = oldContentLines.some(l => l.startsWith('-'));
            if (isMinusLines) {
                patchWithLinesStr = patchWithLinesStr.trimEnd() + '\n__old hunk__\n';
                for (const lineOld of oldContentLines) {
                    patchWithLinesStr += `${lineOld}\n`;
                }
            }
        }
    }

    return patchWithLinesStr.trim();
}

/**
 * Step 1.3: æå–ä¿®æ”¹èŒƒå›´
 */
export function extractLinesFromDiffHunk(diffHunk: string): ModifiedRange[] {
    const lines = diffHunk?.split('\n') || [];
    const modifiedRanges: ModifiedRange[] = [];
    let currentRange: ModifiedRange | null = null;

    for (const line of lines) {
        if (line?.startsWith('@@')) {
            if (currentRange) {
                modifiedRanges.push(currentRange);
                currentRange = null;
            }
            continue;
        }

        if (line?.includes('__new hunk__') || line?.includes('__old hunk__')) {
            continue;
        }

        const lineMatch = line?.match(/^(\d+) ([+-])/);
        if (lineMatch) {
            const lineNumber = parseInt(lineMatch[1], 10);
            const changeType = lineMatch[2];

            if (changeType === '+') {
                if (!currentRange) {
                    currentRange = { start: lineNumber, end: lineNumber };
                } else if (lineNumber === currentRange.end + 1) {
                    currentRange.end = lineNumber;
                } else {
                    modifiedRanges.push(currentRange);
                    currentRange = { start: lineNumber, end: lineNumber };
                }
            }
        } else {
            if (currentRange) {
                modifiedRanges.push(currentRange);
                currentRange = null;
            }
        }
    }

    if (currentRange) {
        modifiedRanges.push(currentRange);
    }

    return modifiedRanges;
}

// ============================================================================
// Step 2: ä¸Šä¸‹æ–‡æ‰©å±•
// ============================================================================

/**
 * Step 2.1: ä»æ–‡ä»¶å†…å®¹ä¸­æå–ä¸ diff ç›¸å…³çš„ä¸Šä¸‹æ–‡
 * æ¨¡æ‹Ÿ getRelatedContentFromDiff çš„æœ¬åœ°å®ç°
 */
export function extractRelevantContext(
    fullFileContent: string,
    modifiedRanges: ModifiedRange[],
    contextLines: number = 15,
): string {
    if (!fullFileContent || !modifiedRanges.length) {
        return fullFileContent || '';
    }

    const lines = fullFileContent.split('\n');
    const relevantLineNumbers = new Set<number>();

    // æ‰©å±•æ¯ä¸ªä¿®æ”¹èŒƒå›´
    for (const range of modifiedRanges) {
        for (let i = range.start - contextLines; i <= range.end + contextLines; i++) {
            if (i >= 1 && i <= lines.length) {
                relevantLineNumbers.add(i);
            }
        }
    }

    // æŒ‰è¡Œå·æ’åºå¹¶ç»„åˆ
    const sortedLines = Array.from(relevantLineNumbers).sort((a, b) => a - b);
    const resultLines: string[] = [];
    let lastLine = -1;

    for (const lineNum of sortedLines) {
        // å¦‚æœæœ‰é—´éš”ï¼Œæ·»åŠ çœç•¥æ ‡è®°
        if (lastLine !== -1 && lineNum > lastLine + 1) {
            resultLines.push(`... (çœç•¥ ${lineNum - lastLine - 1} è¡Œ) ...`);
        }
        resultLines.push(`${lineNum}: ${lines[lineNum - 1]}`);
        lastLine = lineNum;
    }

    return resultLines.join('\n');
}

/**
 * Step 2.2: æ¨¡æ‹Ÿ AST æœåŠ¡çš„ getRelatedContentFromDiff
 * å®é™…æœåŠ¡ä¼šè§£æ AST æ‰¾åˆ°ç›¸å…³çš„å‡½æ•°å’Œç±»
 */
export function mockGetRelatedContentFromDiff(
    fileContent: string,
    diff: string,
    filePath: string,
): { content: string; functions: string[] } {
    // ç®€å•çš„å‡½æ•°æå–ï¼ˆå®é™… AST æœåŠ¡ä¼šæ›´ç²¾ç¡®ï¼‰
    const functionRegex = /(?:function|const|let|var)\s+(\w+)\s*(?:=\s*(?:async\s*)?\(|=\s*(?:async\s*)?function|\()/g;
    const functions: string[] = [];
    let match;

    while ((match = functionRegex.exec(fileContent)) !== null) {
        functions.push(match[1]);
    }

    // æå–ä¿®æ”¹èŒƒå›´é™„è¿‘çš„å‡½æ•°
    const lines = fileContent.split('\n');
    const modifiedRanges = extractLinesFromDiffHunk(diff);
    const relevantFunctions: string[] = [];

    for (const range of modifiedRanges) {
        // æŸ¥æ‰¾åŒ…å«ä¿®æ”¹è¡Œçš„å‡½æ•°
        for (let i = range.start - 1; i >= 0 && i < lines.length; i--) {
            const line = lines[i];
            const funcMatch = line.match(/(?:function|const|let|var)\s+(\w+)/);
            if (funcMatch) {
                if (!relevantFunctions.includes(funcMatch[1])) {
                    relevantFunctions.push(funcMatch[1]);
                }
                break;
            }
        }
    }

    return {
        content: extractRelevantContext(fileContent, modifiedRanges),
        functions: relevantFunctions,
    };
}

// ============================================================================
// Step 3: AST å½±å“åˆ†æ (æ¨¡æ‹Ÿ)
// ============================================================================

/**
 * Step 3.1: æ¨¡æ‹Ÿ AST å½±å“åˆ†æ
 * å®é™…æœåŠ¡ä¼šæ„å»ºå®Œæ•´çš„å‡½æ•°è°ƒç”¨å›¾
 */
export function mockImpactAnalysis(
    fileContent: string,
    modifiedFunctions: string[],
): ImpactAnalysisResponse {
    // ç®€å•çš„è°ƒç”¨å…³ç³»åˆ†æï¼ˆå®é™… AST æœåŠ¡ä¼šæ›´ç²¾ç¡®ï¼‰
    const functionsAffect: FunctionAffect[] = [];

    for (const func of modifiedFunctions) {
        // æŸ¥æ‰¾è°ƒç”¨è¿™ä¸ªå‡½æ•°çš„åœ°æ–¹
        const callerRegex = new RegExp(`\\b${func}\\s*\\(`, 'g');
        const lines = fileContent.split('\n');

        for (let i = 0; i < lines.length; i++) {
            if (callerRegex.test(lines[i])) {
                functionsAffect.push({
                    functionName: func,
                    filePath: 'current-file',
                    impact: `Function ${func} is called at line ${i + 1}`,
                    affectedBy: [func],
                });
            }
        }
    }

    return {
        functionsAffect,
        functionSimilarity: [],
    };
}

// ============================================================================
// Step 4: MCP å·¥å…·è°ƒç”¨ (æ¨¡æ‹Ÿ)
// ============================================================================

/**
 * Step 4.1: æ¨¡æ‹Ÿ MCP å·¥å…·è°ƒç”¨
 */
export function mockMCPToolCall(
    toolName: string,
    args: Record<string, unknown>,
): ContextEvidence {
    // æ¨¡æ‹Ÿä¸åŒå·¥å…·çš„å“åº”
    const mockResponses: Record<string, any> = {
        'code_search': {
            results: [
                { file: 'src/utils.ts', line: 42, content: 'function helper() {...}' },
                { file: 'src/index.ts', line: 15, content: 'import { helper } from "./utils"' },
            ],
        },
        'documentation_lookup': {
            docs: 'This function is used for processing data...',
            examples: ['helper(data)', 'await helper(asyncData)'],
        },
        'dependency_check': {
            dependencies: ['lodash', 'axios'],
            vulnerabilities: [],
        },
    };

    return {
        provider: 'mock-mcp-server',
        toolName,
        payload: mockResponses[toolName] || { message: 'Tool not found' },
        metadata: {
            executionStatus: 'success',
            timestamp: new Date().toISOString(),
        },
    };
}

// ============================================================================
// å®Œæ•´å¤„ç†æµç¨‹
// ============================================================================

export class DiffProcessor {
    private steps: ProcessingStep[] = [];

    /**
     * å¤„ç†å®Œæ•´çš„ PR diffï¼Œè¿”å›æ‰€æœ‰å¤„ç†æ­¥éª¤
     */
    async process(
        file: FileInfo,
        fileContent?: string,
        enableMockAST: boolean = true,
        enableMockMCP: boolean = true,
    ): Promise<AnalysisContext> {
        this.steps = [];
        const startTime = Date.now();

        // Step 1.1: è¿‡æ»¤åªåˆ é™¤çš„ hunks
        const step1Start = Date.now();
        const originalPatch = file.patch || '';
        const filteredPatch = handlePatchDeletions(
            originalPatch,
            file.filename,
            file.status || 'modified',
        );

        this.addStep({
            step: 1,
            name: 'handlePatchDeletions',
            description: 'è¿‡æ»¤åªåŒ…å«åˆ é™¤çš„ hunksï¼Œå‡å°‘ token æ¶ˆè€—',
            input: { patchLength: originalPatch.length },
            output: { filteredPatchLength: filteredPatch?.length || 0 },
            tokensBefore: originalPatch.length,
            tokensAfter: filteredPatch?.length || 0,
            tokensSaved: `${Math.round((1 - (filteredPatch?.length || 0) / Math.max(originalPatch.length, 1)) * 100)}%`,
            duration: Date.now() - step1Start,
        });

        if (!filteredPatch) {
            return {
                file,
                patchWithLinesStr: '',
                modifiedRanges: [],
                processingSteps: this.steps,
            };
        }

        // Step 1.2: æ·»åŠ ç»å¯¹è¡Œå·
        const step2Start = Date.now();
        const patchWithLinesStr = convertToHunksWithLinesNumbers(filteredPatch, file);

        this.addStep({
            step: 2,
            name: 'convertToHunksWithLinesNumbers',
            description: 'æ·»åŠ ç»å¯¹è¡Œå·ï¼Œä¾¿äº LLM ç²¾ç¡®å®šä½',
            input: { filteredPatch: filteredPatch.substring(0, 100) + '...' },
            output: { patchWithLinesStr: patchWithLinesStr.substring(0, 200) + '...' },
            duration: Date.now() - step2Start,
        });

        // Step 1.3: æå–ä¿®æ”¹èŒƒå›´
        const step3Start = Date.now();
        const modifiedRanges = extractLinesFromDiffHunk(patchWithLinesStr);

        this.addStep({
            step: 3,
            name: 'extractLinesFromDiffHunk',
            description: 'æå–ä¿®æ”¹è¡ŒèŒƒå›´ï¼Œç”¨äºè¿‡æ»¤å»ºè®®',
            input: { patchWithLinesStr: '...' },
            output: { modifiedRanges },
            duration: Date.now() - step3Start,
        });

        let relevantContent: string | undefined;
        let impactAnalysis: ImpactAnalysisResponse | undefined;
        const contextEvidences: ContextEvidence[] = [];

        // Step 2: ä¸Šä¸‹æ–‡æ‰©å±•
        if (fileContent) {
            const step4Start = Date.now();
            const contextResult = mockGetRelatedContentFromDiff(
                fileContent,
                patchWithLinesStr,
                file.filename,
            );
            relevantContent = contextResult.content;

            this.addStep({
                step: 4,
                name: 'getRelatedContentFromDiff (æ¨¡æ‹Ÿ)',
                description: 'ä»å®Œæ•´æ–‡ä»¶ä¸­æå–ä¸ diff ç›¸å…³çš„ä»£ç ï¼ˆéæ•´ä¸ªæ–‡ä»¶ï¼‰',
                input: {
                    fullFileLines: fileContent.split('\n').length,
                    modifiedRanges,
                },
                output: {
                    relevantContentLines: relevantContent.split('\n').length,
                    extractedFunctions: contextResult.functions,
                },
                tokensBefore: fileContent.length,
                tokensAfter: relevantContent.length,
                tokensSaved: `${Math.round((1 - relevantContent.length / Math.max(fileContent.length, 1)) * 100)}%`,
                duration: Date.now() - step4Start,
            });

            // Step 3: AST å½±å“åˆ†æ
            if (enableMockAST && contextResult.functions.length > 0) {
                const step5Start = Date.now();
                impactAnalysis = mockImpactAnalysis(fileContent, contextResult.functions);

                this.addStep({
                    step: 5,
                    name: 'initializeImpactAnalysis (æ¨¡æ‹Ÿ)',
                    description: 'åˆ†æä¿®æ”¹å‡½æ•°å¯¹å…¶ä»–å‡½æ•°çš„å½±å“',
                    input: { modifiedFunctions: contextResult.functions },
                    output: {
                        affectedFunctions: impactAnalysis.functionsAffect.length,
                        functionsAffect: impactAnalysis.functionsAffect,
                    },
                    duration: Date.now() - step5Start,
                });
            }
        }

        // Step 4: MCP å·¥å…·è°ƒç”¨
        if (enableMockMCP) {
            const step6Start = Date.now();
            const codeSearchResult = mockMCPToolCall('code_search', {
                query: file.filename,
            });
            contextEvidences.push(codeSearchResult);

            this.addStep({
                step: 6,
                name: 'MCP Tool: code_search (æ¨¡æ‹Ÿ)',
                description: 'Agent è°ƒç”¨ MCP å·¥å…·æœç´¢ç›¸å…³ä»£ç ',
                input: { query: file.filename },
                output: codeSearchResult.payload,
                duration: Date.now() - step6Start,
            });
        }

        // æœ€ç»ˆæ±‡æ€»
        this.addStep({
            step: 99,
            name: 'å¤„ç†å®Œæˆ',
            description: 'æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆï¼Œå‡†å¤‡å‘é€ç»™ LLM',
            input: {},
            output: {
                totalSteps: this.steps.length - 1,
                totalDuration: Date.now() - startTime,
                finalPatchLength: patchWithLinesStr.length,
                modifiedRangesCount: modifiedRanges.length,
                hasRelevantContent: !!relevantContent,
                hasImpactAnalysis: !!impactAnalysis,
                contextEvidencesCount: contextEvidences.length,
            },
            duration: Date.now() - startTime,
        });

        return {
            file,
            patchWithLinesStr,
            modifiedRanges,
            relevantContent,
            impactAnalysis,
            contextEvidences,
            processingSteps: this.steps,
        };
    }

    private addStep(step: ProcessingStep): void {
        this.steps.push(step);
    }

    /**
     * æ‰“å°å¤„ç†æ­¥éª¤ï¼ˆç”¨äºè°ƒè¯•ï¼‰
     */
    static printSteps(context: AnalysisContext): void {
        console.log('\n' + '='.repeat(80));
        console.log('ğŸ“Š PR Diff å¤„ç†æµç¨‹è¯¦æƒ…');
        console.log('='.repeat(80));
        console.log(`ğŸ“ æ–‡ä»¶: ${context.file.filename}`);
        console.log('='.repeat(80));

        for (const step of context.processingSteps) {
            console.log(`\nğŸ“Œ Step ${step.step}: ${step.name}`);
            console.log(`   æè¿°: ${step.description}`);
            console.log(`   è€—æ—¶: ${step.duration}ms`);

            if (step.tokensBefore !== undefined && step.tokensAfter !== undefined) {
                console.log(`   Token: ${step.tokensBefore} â†’ ${step.tokensAfter} (èŠ‚çœ ${step.tokensSaved})`);
            }

            console.log(`   è¾“å…¥:`, JSON.stringify(step.input, null, 2).split('\n').map(l => '      ' + l).join('\n'));
            console.log(`   è¾“å‡º:`, JSON.stringify(step.output, null, 2).split('\n').map(l => '      ' + l).join('\n'));
        }

        console.log('\n' + '='.repeat(80));
        console.log('âœ… æœ€ç»ˆè¾“å‡ºï¼ˆå‘é€ç»™ LLM çš„å†…å®¹ï¼‰');
        console.log('='.repeat(80));
        console.log('\n--- patchWithLinesStr ---');
        console.log(context.patchWithLinesStr);

        if (context.relevantContent) {
            console.log('\n--- relevantContent (ç›¸å…³ä»£ç ä¸Šä¸‹æ–‡) ---');
            console.log(context.relevantContent);
        }

        if (context.impactAnalysis?.functionsAffect?.length) {
            console.log('\n--- impactAnalysis (å½±å“åˆ†æ) ---');
            console.log(JSON.stringify(context.impactAnalysis, null, 2));
        }

        console.log('\n' + '='.repeat(80));
    }
}

export default DiffProcessor;
